{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science 2025\n",
    "\n",
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 | Matrix warm-up\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in the course material.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful properties of any scientific programming language (Python with NumPy, R, Julia, etc) is that they allow us to work with matrices efficiently. Let's learn more about these features!\n",
    "\n",
    "### 1.1 Basics\n",
    "\n",
    "1. Let's start by creating two arrays <span style=\"background-color: #ccfff2\"> A</span> and <span style=\"background-color: #ccfff2\"> B</span> which each have the integers <span style=\"background-color: #ccfff2\"> 0, 1, 2, ..., 1e7-1</span>. Use the normal arrays or lists of the programming language you are using, e.g. *list* or *[ ]* or *numpy.array()* in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = list(range(int(1e7)))\n",
    "B = list(range(int(1e7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that uses a <span style=\"background-color: #ccfff2\"> for loop</span> or equivalent to return a new array <span style=\"background-color: #ccfff2\"> C</span>, which contains the <span style=\"background-color: #ccfff2\"> element-wise sum of *A* and *B*</span>, e.g. C should contain the integers <span style=\"background-color: #ccfff2\"> 0, 2, 4, etc</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_with_for(A,B):\n",
    "    C = []\n",
    "    for i in range(len(A)):\n",
    "        C.append(A[i] + B[i])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, let's create another function that uses NumPy (or equivalent) to do the same. To try it out, allocate two arrays (e.g. using <span style=\"background-color: #ccfff2\"> np.array</span> in NumPy) and add the arrays together using your function. Don't use loops, instead, find out how to add the two arrays directly. What do you notice in comparison to the previous function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_direct(A,B):\n",
    "    A_numpy = np.array(A)\n",
    "    B_numpy = np.array(B)\n",
    "    C_numpy = A_numpy + B_numpy\n",
    "    return C_numpy.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #ccfff2\"> *Note: for the following exercises, only use NumPy or equivalent functions. Don't use any loops.* </span>\n",
    "1. Create the following array:\n",
    "\n",
    "*[hint: <span style=\"background-color: #ccfff2\"> np.reshape</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
    "#        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "#        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "#        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "#        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "#        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "#        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "#        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "#        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
    "#        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(100).reshape(10, 10)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "array = np.tile([0., 1.],(10,5))\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the following array (D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "D = np.ones((10,10))\n",
    "np.fill_diagonal(D, 0)\n",
    "print(D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the following array (E):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "E = np.fliplr(D)\n",
    "print(E) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Call the last two matrices <span style=\"background-color: #ccfff2\">D</span> and <span style=\"background-color: #ccfff2\">E</span>, respectively. Show that the determinant of their product (matrix multiplication) is the same as the product of their determinants. That is calculate both <span style=\"background-color: #ccfff2\">det(DE)</span> and <span style=\"background-color: #ccfff2\">det(D) * det(E)</span>, and show that they are the same. Is it a coincidence? (I think not) The product of the determinants (or the determinant of the product) should be -81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-81.0\n",
      "-81.00000000000003\n"
     ]
    }
   ],
   "source": [
    "DE = np.dot(D, E)\n",
    "det_DE = np.linalg.det(DE)\n",
    "det_D = np.linalg.det(D)\n",
    "det_E = np.linalg.det(E)\n",
    "print(det_D * det_E)\n",
    "print(det_DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a coincidence. By the property of determinants, we know this well held, and the only difference between -81.0 and -81.00000000000003 is due to floating-point computation errors by computer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Slicing\n",
    "\n",
    "Array slicing is a powerful way to extract data from an array. Let's practice array slicing with the following exercises!\n",
    "\n",
    "1. Load the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). The data should be a matrix of shape <span style=\"background-color: #ccfff2\">(20640, 8)</span>, that is 20640 rows and 8 columns. Use the <span style=\"background-color: #ccfff2\">.shape</span> attribute of NumPy arrays to verify this. Here's a [description of the fields](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "print(np.shape(data.data))\n",
    "list(data.feature_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select rows where the average number of bedrooms <span style=\"background-color: #ccfff2\">(AveBedrms)</span> is higher than 2. The first few row indices should be <span style=\"background-color: #ccfff2\">710,  1023,  1024, ...</span> (zero-indexed). Count these houses - how many rows are selected? *[hint: <span style=\"background-color: #ccfff2\">np.where</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  710  1023  1024  1030  1102  1233  1234  1235  1236  1238  1239  1240\n",
      "  1566  1867  1871  1872  1879  1881  1889  1901  1906  1910  1911  1912\n",
      "  1913  1914  1925  1926  1978  1979  2392  2395  2396  2397  2398  2510\n",
      "  2511  2643  2656  2763  2768  2776  2778  3014  3086  3095  3258  3292\n",
      "  3293  3313  3314  3334  3349  3350  9193  9423  9431  9451  9634  9669\n",
      "  9671  9672  9675  9676  9678  9679  9680  9681  9682  9683 10067 10076\n",
      " 10077 10078 10079 10080 10081 10082 10083 10084 10405 11705 11706 11707\n",
      " 11708 11709 11710 11711 11713 11714 11715 11716 11717 11719 11720 11721\n",
      " 11722 11723 11724 11725 11729 11831 11832 11833 11834 11847 11848 11849\n",
      " 11850 11862 11865 11866 11867 11869 11870 12136 12303 12305 12306 12307\n",
      " 12324 12325 12344 12349 12351 12354 12359 12361 12362 12366 12368 12371\n",
      " 12372 12374 12376 12390 12392 12394 12396 12404 12405 12430 12446 12447\n",
      " 13898 13900 13911 13912 13919 13920 13923 13924 13934 13935 13936 13937\n",
      " 13939 13940 13941 13942 13943 13944 13945 13946 13947 13948 13949 13950\n",
      " 13953 13954 13955 13956 13957 13958 13959 13960 13961 13962 13963 13964\n",
      " 13965 13966 13967 13968 13969 13970 13971 13972 13973 13974 13975 13976\n",
      " 13978 13979 13980 13999 14417 14418 14805 15500 15595 15779 16598 17878\n",
      " 17891 18680 18681 18817 18821 18822 18858 19331 19362 19435 19536 19736\n",
      " 19780 19781 19789 19800 19801 19802 19803 19806 19807 19975 19976 19977\n",
      " 20089 20092 20093 20094 20110 20112 20113]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(data.data[:,3] > 2)[0]\n",
    "print(idx)\n",
    "np.size(idx)# roles selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select the rows where the median house age (i.e. median in each block group) <span style=\"background-color: #ccfff2\">(HouseAge)</span> is between 1 and 3 years (inclusive). There should be **124** of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   59   854   871   959   976  1260  1565  1566  1648  1719  2206  2310\n",
      "  2311  2312  2336  2339  2706  2774  2993  3130  3140  5506  9109  9132\n",
      "  9147  9168  9187  9378  9639 10336 10376 10391 10401 10403 10406 10410\n",
      " 10412 10416 10440 10456 10467 10513 10514 10519 10521 10524 10525 10529\n",
      " 10548 10619 10622 10631 11490 11775 12000 12006 12077 12084 12119 12123\n",
      " 12137 12142 12143 12151 12156 12167 12171 12201 12202 12203 12204 12285\n",
      " 12286 12308 12363 12430 12841 12868 13041 13074 13100 13102 13139 13177\n",
      " 13179 13367 13368 13373 13374 13375 13422 13659 13713 13715 13747 13848\n",
      " 13855 14557 15220 15444 15464 15736 15785 16383 16566 16593 17068 17824\n",
      " 17826 17827 18725 18942 18947 18972 18989 19001 19003 19033 19046 19536\n",
      " 19561 19650 20070 20367]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where((data.data[:,1] >= 1) & (data.data[:,1] <= 3))[0]\n",
    "print(idx)\n",
    "np.size(idx)# roles selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the mean of the block group population <span style=\"background-color: #ccfff2\">(Population)</span> for homes whose median value is more than 25000 USD (the target variable). It should be around **1425.68**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425.4767441860465\n"
     ]
    }
   ],
   "source": [
    "population = np.where(data.data[:,4] > 2.5)[0]\n",
    "mean_population = np.mean(data.data[population,4])\n",
    "print(mean_population)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 | Working with text data\n",
    "\n",
    "Next, let's look into some text data. We will be looking into Amazon reviews, and the necessary steps to transform a raw dataset into a format more suitable for prediction tasks.\n",
    "\n",
    "1. Download the automotive 5-core dataset from [here](https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Automotive_5.json.gz). Next, you can extract the data in <span style=\"background-color: #ccfff2\">JSON</span> format. You can also download one of the bigger ones, if you are feeling ambitious. Open the JSON file. Access the <span style=\"background-color: #ccfff2\">reviewText</span> field, which contains the unstructured review text written by the user.\n",
    "\n",
    "For instance, the first review reads as follows: \n",
    "\n",
    "*'After I wrote the below review, the manufacturer contacted me and explained how to use this.  Instead of the (current) picture on Amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally. [...]'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
      "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n",
      "       'image'],\n",
      "      dtype='object')\n",
      "0          After I wrote the below review, the manufactur...\n",
      "1          It sucks barely picks up anything definitely n...\n",
      "2          Well to write a short one, it blew 2 fuses of ...\n",
      "3          I have absolutely no memory of buying this but...\n",
      "4                                       it ok it does it job\n",
      "                                 ...                        \n",
      "1711514                          Fast Shipping, Works Great!\n",
      "1711515    Fit isn't great, relays are very hard to press...\n",
      "1711516    I bought an auxiliary horn for my car and it n...\n",
      "1711517    Way better than stock. Nice bright and white. ...\n",
      "1711518    Great product fast shipping and awesome commun...\n",
      "Name: reviewText, Length: 1711519, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "df = pd.read_json('Automotive_5.json', lines=True)\n",
    "print(df.columns)\n",
    "review_texts = df['reviewText']\n",
    "print(review_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's follow some steps to normalize the text data.\n",
    "\n",
    "When dealing with natural language, it is important to notice that while, for example, the words \"Copper\" and \"copper\" are represented by two different strings, they have the same meaning. When applying statistical methods on this data, it is useful to ensure that words with the same meaning are represented by the same string.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Downcasing</span>: Let's first downcase the contents of the <span style=\"background-color: #ccfff2\">reviewText</span> field.\n",
    "\n",
    "Now the first review should be:\n",
    "\n",
    "*'after i wrote the below review, the manufacturer contacted me and explained how to use this.  instead of the (current) picture on amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          after i wrote the below review, the manufactur...\n",
      "1          it sucks barely picks up anything definitely n...\n",
      "2          well to write a short one, it blew 2 fuses of ...\n",
      "3          i have absolutely no memory of buying this but...\n",
      "4                                       it ok it does it job\n",
      "                                 ...                        \n",
      "1711514                          fast shipping, works great!\n",
      "1711515    fit isn't great, relays are very hard to press...\n",
      "1711516    i bought an auxiliary horn for my car and it n...\n",
      "1711517    way better than stock. nice bright and white. ...\n",
      "1711518    great product fast shipping and awesome commun...\n",
      "Name: reviewText, Length: 1711519, dtype: object\n"
     ]
    }
   ],
   "source": [
    "texts_lower = df['reviewText'].str.lower()\n",
    "print(texts_lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's continue with punctuation and stop word removal. Stop words are words like \"and\", \"the\", etc. They are usually very common words that have little to do with the actual content matter. There's plenty openly available lists of stop words for almost any (natural) language.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Punctuation and stop-word removal</span>: Let's now remove all punctuation, as well as the stop words. You can find a stop word list for English, e.g. [here](https://gist.github.com/xldrkp/4a3b1a33f10d37bedbe0068f2b4482e8#file-stopwords-en-txt).*(use the link to download a txt of english stopwords)* Save the stopwords in the file as \"stopwords-en.txt\".\n",
    "\n",
    "First review at this point reads as: \n",
    "\n",
    "*'wrote review manufacturer contacted explained current picture amazon phone vertically stand phone horizontally'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          wrote review manufacturer contacted explained ...\n",
      "1          sucks barely picks definitely cars pretty don ...\n",
      "2          write short blew 2 fuses car apparently demand...\n",
      "3          absolutely memory buying m going review goes a...\n",
      "4                                                ok does job\n",
      "                                 ...                        \n",
      "1711514                            fast shipping works great\n",
      "1711515    fit isn t great relays hard press connector me...\n",
      "1711516    bought auxiliary horn car needed run relay guy...\n",
      "1711517    way better stock nice bright white super easy ...\n",
      "1711518    great product fast shipping awesome communicat...\n",
      "Name: reviewText, Length: 1711519, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "with open('stopwords-en.txt', 'r') as file:\n",
    "      stopwords = set(file.read().strip().split('\\n'))\n",
    "def remove_punctuation(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ',text)\n",
    "    words = [word for word in text.split() if word not in stopwords]\n",
    "    return ' '.join(words)\n",
    "texts_cleaned = texts_lower.apply(remove_punctuation)\n",
    "print(texts_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's continue with stemming. For example, while the words \"swims\" and \"swim\" are different strings, they both refer to swimming. [Stemming](https://en.wikipedia.org/wiki/Stemming) refers to the process of mapping words from their inflected form to their base form, for instance: swims -> swim.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Stemming</span>: Apply a stemmer on the paragraphs, so that inflected forms are mapped to the base form. For example, for Python the popular natural language toolkit [nltk](http://www.nltk.org/howto/stem.html) has an easy to use stemmer. In case you are using R, you can try the [Snowball stemmer](https://www.rdocumentation.org/packages/corpus/versions/0.10.2/topics/stem_snowball). You can find out how to install nltk from [here](https://www.nltk.org/install.html). It will take a while to run! So, grab a coffee and wait :D\n",
    "\n",
    "Finally, after stemming: \n",
    "\n",
    "*'wrote review manufactur contact explain current pictur amazon phone vertic stand phone horizont'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          wrote review manufactur contact explain use in...\n",
      "1          suck bare pick definit car pretti don t wast m...\n",
      "2               write short blew 2 fuse car appar demand 12v\n",
      "3          absolut memori buy m go review goe away review...\n",
      "4                                                 ok doe job\n",
      "                                 ...                        \n",
      "1711514                                 fast ship work great\n",
      "1711515    fit isn t great relay hard press connector mechan\n",
      "1711516    bought auxiliari horn car need run relay guy f...\n",
      "1711517    way better stock nice bright white super easi ...\n",
      "1711518    great product fast ship awesom commun product ...\n",
      "Name: reviewText, Length: 1711519, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "texts_stem = texts_cleaned.apply(lambda _: ' '.join([stemmer.stem(word) for word in _.split()]))\n",
    "print(texts_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, filter the data by selecting reviews where the field <span style=\"background-color: #ccfff2\">overall</span> is 4 or 5, and store the review texts in a file named <span style=\"background-color: #ccfff2\">pos.txt</span>. Similarly, select reviews with rating 1 or 2 and store them in a file named <span style=\"background-color: #ccfff2\">neg.txt</span>. Ignore the reviews with overall rating 3. Each line in the two files should contain exactly one preprocessed review text without the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review = texts_stem[df['overall'].isin([4, 5])]\n",
    "neg_review = texts_stem[df['overall'].isin([1, 2])]\n",
    "pos_review.to_csv('pos.txt', index=False)\n",
    "neg_review.to_csv('neg.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 | SQL basics\n",
    "\n",
    "Next, let's take a refresher on the basics of SQL. In this exercise, you will be working on the simplified Northwind 2000 SQLite database. You can download the database from Kaggle [here](https://courses.mooc.fi/api/v0/files/course/f92ffc32-2dd4-421d-87f3-c48800422cc5/files/VEKX2bxGCDGyojG902gmYZTXCnrAQw.zip).\n",
    "\n",
    "To test your SQL queries and complete the exercise, you can download and install SQLite if you don't yet have it installed.\n",
    "\n",
    "Please write SQL queries for the tasks on the simplified Northwind 2000 SQLite database.\n",
    "\n",
    "1. List the first name, last name, and hire date of all employees hired after January 1st, 1994.\n",
    "\n",
    "    SELECT FirstName,LastName, HireDate FROM Employees WHERE HireDate > '1994-01-01'; \n",
    "\n",
    "\n",
    "2. Count how many orders each customer has placed. \n",
    "\n",
    "    SELECT CustomerID, COUNT(*) FROM Orders GROUP BY CustomerID;\n",
    "\n",
    "\n",
    "3. Find the names of all customers who have ordered the product \"Chai\".\n",
    "\n",
    "    SELECT DISTINCT c.CompanyName FROM Customers c \n",
    "    JOIN Orders o ON c.CustomerID = o.CustomerID \n",
    "    JOIN OrderDetails od ON o.OrderID = od.OrderID \n",
    "    JOIN Products p ON od.ProductID = p.ProductID WHERE p.ProductName = 'Chai';\n",
    "\n",
    "\n",
    "4. Find all orders that have been placed but not yet shipped. \n",
    "\n",
    "    SELECT * FROM Orders WHERE ShippedDate IS NULL\n",
    "\n",
    "\n",
    "\n",
    "5. Find the customer who has placed the most orders.\n",
    "\n",
    "    SELECT CustomerID,COUNT(*) FROM Orders GROUP BY CustomerID ORDER BY COUNT(*) DESC LIMIT 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Categories',), ('sqlite_sequence',), ('Customers',), ('Employees',), ('OrderDetails',), ('Orders',), ('Products',), ('Shippers',), ('Suppliers',)]\n",
      "[('Robert', 'King', '1994-01-02'), ('Laura', 'Callahan', '1994-03-05'), ('Anne', 'Dodsworth', '1994-11-15')]\n",
      "[('ALFKI', 6), ('ANATR', 4), ('ANTON', 7), ('AROUT', 13), ('BERGS', 18), ('BLAUS', 7), ('BLONP', 11), ('BOLID', 3), ('BONAP', 17), ('BOTTM', 14), ('BSBEV', 10), ('CACTU', 6), ('CENTC', 1), ('CHOPS', 8), ('COMMI', 5), ('CONSH', 3), ('DRACD', 6), ('DUMON', 4), ('EASTC', 8), ('ERNSH', 30), ('FAMIA', 7), ('FOLIG', 5), ('FOLKO', 19), ('FRANK', 15), ('FRANR', 3), ('FRANS', 6), ('FURIB', 8), ('GALED', 5), ('GODOS', 10), ('GOURL', 9), ('GREAL', 11), ('GROSR', 2), ('HANAR', 14), ('HILAA', 18), ('HUNGC', 5), ('HUNGO', 19), ('ISLAT', 10), ('KOENE', 14), ('LACOR', 4), ('LAMAI', 14), ('LAUGB', 3), ('LAZYK', 2), ('LEHMS', 15), ('LETSS', 4), ('LILAS', 14), ('LINOD', 12), ('LONEP', 8), ('MAGAA', 10), ('MAISD', 7), ('MEREP', 13), ('MORGK', 5), ('NORTS', 3), ('OCEAN', 5), ('OLDWO', 10), ('OTTIK', 10), ('PERIC', 6), ('PICCO', 10), ('PRINI', 5), ('QUEDE', 9), ('QUEEN', 13), ('QUICK', 28), ('RANCH', 5), ('RATTC', 18), ('REGGC', 12), ('RICAR', 11), ('RICSU', 10), ('ROMEY', 5), ('SANTG', 6), ('SAVEA', 31), ('SEVES', 9), ('SIMOB', 7), ('SPECD', 4), ('SPLIR', 9), ('SUPRD', 12), ('THEBI', 4), ('THECR', 3), ('TOMSP', 6), ('TORTU', 10), ('TRADH', 6), ('TRAIH', 3), ('VAFFE', 11), ('VICTE', 10), ('VINET', 5), ('WANDK', 10), ('WARTH', 15), ('WELLI', 9), ('WHITC', 14), ('WILMK', 7), ('WOLZA', 7)]\n",
      "[('QUICK-Stop',), ('Rattlesnake Canyon Grocery',), ('Lonesome Pine Restaurant',), ('Die Wandernde Kuh',), ('Pericles Comidas clásicas',), ('Chop-suey Chinese',), ('Queen Cozinha',), (\"La maison d'Asie\",), ('Princesa Isabel Vinhos',), ('Lehmanns Marktstand',), ('Wartian Herkku',), ('Tortuga Restaurante',), ('Mère Paillarde',), ('Du monde entier',), ('Wolski  Zajazd',), ('Blondesddsl père et fils',), ('Hungry Owl All-Night Grocers',), ('Berglunds snabbköp',), ('Save-a-lot Markets',), ('LINO-Delicateses',), ('North/South',), ('HILARION-Abastos',), ('Seven Seas Imports',), ('Wellington Importadora',), ('Godos Cocina Típica',), ('Bottom-Dollar Markets',), ('The Cracker Box',), ('Wilman Kala',), ('Great Lakes Food Market',), ('Suprêmes délices',), ('Eastern Connection',)]\n",
      "[(11008, 'ERNSH', 7, '1998-04-08 00:00:00.000', '1998-05-06 00:00:00.000', None, 3, 79.46), (11019, 'RANCH', 6, '1998-04-13 00:00:00.000', '1998-05-11 00:00:00.000', None, 3, 3.17), (11039, 'LINOD', 1, '1998-04-21 00:00:00.000', '1998-05-19 00:00:00.000', None, 2, 65), (11040, 'GREAL', 4, '1998-04-22 00:00:00.000', '1998-05-20 00:00:00.000', None, 3, 18.84), (11045, 'BOTTM', 6, '1998-04-23 00:00:00.000', '1998-05-21 00:00:00.000', None, 2, 70.58), (11051, 'LAMAI', 7, '1998-04-27 00:00:00.000', '1998-05-25 00:00:00.000', None, 3, 2.79), (11054, 'CACTU', 8, '1998-04-28 00:00:00.000', '1998-05-26 00:00:00.000', None, 1, 0.33), (11058, 'BLAUS', 9, '1998-04-29 00:00:00.000', '1998-05-27 00:00:00.000', None, 3, 31.14), (11059, 'RICAR', 2, '1998-04-29 00:00:00.000', '1998-06-10 00:00:00.000', None, 2, 85.8), (11061, 'GREAL', 4, '1998-04-30 00:00:00.000', '1998-06-11 00:00:00.000', None, 3, 14.01), (11062, 'REGGC', 4, '1998-04-30 00:00:00.000', '1998-05-28 00:00:00.000', None, 2, 29.93), (11065, 'LILAS', 8, '1998-05-01 00:00:00.000', '1998-05-29 00:00:00.000', None, 1, 12.91), (11068, 'QUEEN', 8, '1998-05-04 00:00:00.000', '1998-06-01 00:00:00.000', None, 2, 81.75), (11070, 'LEHMS', 2, '1998-05-05 00:00:00.000', '1998-06-02 00:00:00.000', None, 1, 136), (11071, 'LILAS', 1, '1998-05-05 00:00:00.000', '1998-06-02 00:00:00.000', None, 1, 0.93), (11072, 'ERNSH', 4, '1998-05-05 00:00:00.000', '1998-06-02 00:00:00.000', None, 2, 258.64), (11073, 'PERIC', 2, '1998-05-05 00:00:00.000', '1998-06-02 00:00:00.000', None, 2, 24.95), (11074, 'SIMOB', 7, '1998-05-06 00:00:00.000', '1998-06-03 00:00:00.000', None, 2, 18.44), (11075, 'RICSU', 8, '1998-05-06 00:00:00.000', '1998-06-03 00:00:00.000', None, 2, 6.19), (11076, 'BONAP', 4, '1998-05-06 00:00:00.000', '1998-06-03 00:00:00.000', None, 2, 38.28), (11077, 'RATTC', 1, '1998-05-06 00:00:00.000', '1998-06-03 00:00:00.000', None, 2, 8.53)]\n",
      "[('SAVEA', 31)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('northwind2000-simplified.sqlite')\n",
    "print(conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall())\n",
    "print(conn.execute(\"SELECT FirstName,LastName, HireDate FROM Employees WHERE HireDate > '1994-01-01'\").fetchall())\n",
    "print(conn.execute(\"SELECT CustomerID,COUNT(*) FROM Orders GROUP BY CustomerID\").fetchall())\n",
    "print(conn.execute(\"SELECT DISTINCT c.CompanyName FROM Customers c JOIN Orders o ON c.CustomerID = o.CustomerID JOIN OrderDetails od ON o.OrderID = od.OrderID JOIN Products p ON od.ProductID = p.ProductID WHERE p.ProductName = 'Chai'\").fetchall())\n",
    "print(conn.execute(\"SELECT * FROM Orders WHERE ShippedDate IS NULL\").fetchall())\n",
    "print(conn.execute(\"SELECT CustomerID,COUNT(*) FROM Orders GROUP BY CustomerID ORDER BY COUNT(*) DESC LIMIT 1\").fetchall())\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your solutions. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences. Remember to also submit your SQL queries. No need to submit the text files for the programming exercises.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
